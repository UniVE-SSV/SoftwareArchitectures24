<!DOCTYPE html>

<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
		<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Search | Software Architectures</title>
<meta name="generator" content="Jekyll v4.3.3" />
<meta property="og:title" content="Search" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Product documentation template for Jekyll." />
<meta property="og:description" content="Product documentation template for Jekyll." />
<link rel="canonical" href="http://localhost:4000/search/" />
<meta property="og:url" content="http://localhost:4000/search/" />
<meta property="og:site_name" content="Software Architectures" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Search" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"Product documentation template for Jekyll.","headline":"Search","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/siteicon.png"}},"url":"http://localhost:4000/search/"}</script>
<!-- End Jekyll SEO tag -->

		<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Software Architectures" />

		<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400,400italic,700,700italic|Open+Sans:400,400italic,600,600italic,700,700italic|Inconsolata:400,700|Roboto:ital,wght@0,100;1,100&display=swap">
		<link rel="stylesheet" href="/css/main.css">
		<link rel="apple-touch-icon" href="/apple-touch-icon.png">
		<link rel="icon" type="image/png" href="/touch-icon.png" sizes="192x192">
		<link rel="icon" type="image/png" href="/images/favicon.png">

		<!-- -->
	</head>

	<body>
		<header>
			<h1>
				<a href="/"><img src="/images/emblem.svg" width="40" height="40" alt="Software Architectures logo"></a>
				Software Architectures
				<button type="button" class="open-nav" id="open-nav"></button>
			</h1>

			<form action="/search/" method="get">
				<input type="text" name="q" id="search-input" placeholder="Search" autofocus>
				<input type="submit" value="Search" style="display: none;">
			</form>

			<nav >
				<ul>
					<li class="nav-item top-level ">
						
						<a href="/">Home</a>
					</li>
				</ul>

				<ul>
					
					
						<li class="nav-item top-level ">
							
							<a href="/gradle/introduction/">02. Gradle</a>
							<ul>
								
									<li class="nav-item "><a href="/gradle/introduction/">1. Introduction</a></li>
								
									<li class="nav-item "><a href="/gradle/build.gradle/">2. build.gradle</a></li>
								
									<li class="nav-item "><a href="/gradle/testing-java-applications/">3. Testing Java Applications</a></li>
								
									<li class="nav-item "><a href="/gradle/example-log4j/">4. Example - log4j</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/docker/introduction/">1. Docker</a>
							<ul>
								
									<li class="nav-item "><a href="/docker/introduction/">1. Introduction</a></li>
								
									<li class="nav-item "><a href="/docker/getting-started/">2. Getting Started</a></li>
								
									<li class="nav-item "><a href="/docker/cli-and-dockerfile/">3. CLI and Dockerfile</a></li>
								
									<li class="nav-item "><a href="/docker/volumes/">4. Volumes</a></li>
								
							</ul>
						</li>
					
				</ul>

				<ul>
					<li class="nav-item top-level ">
						
						<a href="/changelog/"></a>
					</li>
				</ul>
			</nav>
		</header>

		<section class="main">
			<div class="page-header">
				<h2>Software Architectures</h2>
				<h3>Search</h3>
			</div>
			<article class="content">
				<p><span id="search-process">Loading</span> results <span id="search-query-container" style="display: none;">for "<strong id="search-query"></strong>"</span></p>
<ul id="search-results"></ul>

<script>
	window.data = {
		
			
				
					
					

					"docker-cli-and-dockerfile": {
						"id": "docker-cli-and-dockerfile",
						"title": "3. CLI and Dockerfile",
						"category": "",
						"url": " /docker/cli-and-dockerfile/",
						"content": "Contents The Docker CLI Show all the downloaded images Download an image from the Docker Hub List, create, and run containers Build an image Other commands The Dockerfile RUN and CMD: what’s the difference? Build the image Other Dockerfile commands Exercises In the previous sections, we talked about Docker and we saw how we can download an image and launch a container. Here, we are going to explain how to interact with the Docker daemon using the Docker CLI and how we can create our custom images. The Docker CLI The Docker Engine is shipped out with a docker CLI client application. You can interact with docker using the docker command: ~ Projects sw-arch docker docker Usage: docker [OPTIONS] COMMAND A self-sufficient runtime for containers Common Commands: run Create and run a new container from an image exec Execute a command in a running container ps List containers build Build an image from a Dockerfile pull Download an image from a registry push Upload an image to a registry images List images login Log in to a registry logout Log out from a registry search Search Docker Hub for images version Show the Docker version information info Display system-wide information Management Commands: builder Manage builds buildx* Docker Buildx (Docker Inc., v0.11.2-desktop.1) compose* Docker Compose (Docker Inc., v2.20.2-desktop.1) container Manage containers context Manage contexts dev* Docker Dev Environments (Docker Inc., v0.1.0) extension* Manages Docker extensions (Docker Inc., v0.2.20) image Manage images init* Creates Docker-related starter files for your project (Docker Inc., v0.1.0-beta.6) manifest Manage Docker image manifests and manifest lists network Manage networks plugin Manage plugins sbom* View the packaged-based Software Bill Of Materials (SBOM) for an image (Anchore Inc., 0.6.0) scan* Docker Scan (Docker Inc., v0.26.0) scout* Command line tool for Docker Scout (Docker Inc., 0.20.0) system Manage Docker trust Manage trust on Docker images volume Manage volumes Swarm Commands: swarm Manage Swarm Commands: attach Attach local standard input, output, and error streams to a running container commit Create a new image from a container's changes cp Copy files folders between a container and the local filesystem create Create a new container diff Inspect changes to files or directories on a container's filesystem events Get real time events from the server export Export a container's filesystem as a tar archive history Show the history of an image import Import the contents from a tarball to create a filesystem image inspect Return low-level information on Docker objects kill Kill one or more running containers load Load an image from a tar archive or STDIN logs Fetch the logs of a container pause Pause all processes within one or more containers port List port mappings or a specific mapping for the container rename Rename a container restart Restart one or more containers rm Remove one or more containers rmi Remove one or more images save Save one or more images to a tar archive (streamed to STDOUT by default) start Start one or more stopped containers stats Display a live stream of container(s) resource usage statistics stop Stop one or more running containers tag Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE top Display the running processes of a container unpause Unpause all processes within one or more containers update Update configuration of one or more containers wait Block until one or more containers stop, then print their exit codes Global Options: --config string Location of client config files (default \" Users giacomo .docker\") -c, --context string Name of the context to use to connect to the daemon (overrides DOCKER_HOST env var and default context set with \"docker context use\") -D, --debug Enable debug mode -H, --host list Daemon socket to connect to -l, --log-level string Set the logging level (\"debug\", \"info\", \"warn\", \"error\", \"fatal\") (default \"info\") --tls Use TLS; implied by --tlsverify --tlscacert string Trust certs signed only by this CA (default \" Users giacomo .docker ca.pem\") --tlscert string Path to TLS certificate file (default \" Users giacomo .docker cert.pem\") --tlskey string Path to TLS key file (default \" Users giacomo .docker key.pem\") --tlsverify Use TLS and verify the remote -v, --version Print version information and quit Run 'docker COMMAND --help' for more information on a command. For more help on how to use Docker, head to https: docs.docker.com go guides Docker CLI commands are self-explanatory: however, we will see briefly the most important ones. Show all the downloaded images You can get a list of all the images that you have downloaded with the command docker images (or docker image ls): ~ Projects sw-arch docker docker images REPOSITORY TAG IMAGE ID CREATED SIZE golang latest 57ca605b665e 12 hours ago 814MB httpd latest 7860e7628717 31 hours ago 168MB docker getting-started latest 3e4394f6b72f 8 months ago 47MB Download an image from the Docker Hub What about downloading an image? Just type docker pull &lt;name-of-image:tag&gt; (example: docker pull nodejs:latest). Tag permits you to specify which version of the Docker image you want to use. If you don’t specify a tag, the latest available image will be pulled. You can see all the available tags for an image directly from the Docker Hub (for example, for node: hub.docker.com _ node tags). ~ Projects sw-arch docker docker pull node:latest latest: Pulling from library node 012c0b3e998c: Already exists 00046d1e755e: Already exists 9f13f5a53d11: Already exists e13e76ad6279: Pull complete 95103e803d28: Pull complete c3ef23edee6c: Pull complete cde810d34647: Pull complete cfeacc2c3f89: Pull complete Digest: sha256:69cf8e7dcc78e63db74ca6ed570e571e41029accdac21b219b6ac57e9aca63cf Status: Downloaded newer image for node:latest docker.io library node:latest What's Next? View summary of image vulnerabilities and recommendations → docker scout quickview node:latest ~ Projects sw-arch docker docker images REPOSITORY TAG IMAGE ID CREATED SIZE node latest add6f751ed2b 11 hours ago 1.1GB golang latest 57ca605b665e 13 hours ago 814MB httpd latest 7860e7628717 32 hours ago 168MB docker getting-started latest 3e4394f6b72f 8 months ago 47MB ~ Projects sw-arch docker As we mentioned before, an image is composed of layers, that are images themselves. When you download an image, you download the layers that compose that image and this is visible by the logs of the docker pull command (i.e., 012c0b3e998c, 00046d1e755e, 9f13f5a53d11 are the first three layers that compose this image). This permits you to avoid redownloading a layer if you have already pulled it for another image. In the example above, we have that the first three layers already exist locally, so Docker skips the download of these layers. The downloaded image is then visible inside Docker Desktop: List, create, and run containers To create a container from an image, you can use the docker create command: ~ Projects sw-arch docker docker create -p 8080:80 httpd 597372a315efb6465d2900a2cabb7b570b6cee884cf87781927443365435cd75 With the -p flag you can specify the port mapping: in the example, we map port 8080 of the host to port 80 in the container. If you want to see all the available containers in your docker environment, you can use docker ps -a command: ~ Projects sw-arch docker docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 597372a315ef httpd \"httpd-foreground\" 50 seconds ago Created tender_banzai 7e1bd280a489 node:18 \"docker-entrypoint.s…\" 3 days ago Exited (0) 3 days ago happy_lalande c9338f41f0dc docker getting-started \" docker-entrypoint.…\" 3 days ago Exited (255) 6 minutes ago 0.0.0.0:80-&gt;80 tcp great_lehmann 7d7fb37297b2 docker getting-started:latest \" docker-entrypoint.…\" 4 days ago Up About a minute 0.0.0.0:1234-&gt;80 tcp romantic_elgamal c39fccc5e710 docker getting-started:latest \" docker-entrypoint.…\" 4 days ago Exited (0) 3 days ago ~ Projects sw-arch docker To start a container, you can use the docker start command, passing the ID of the desired container: ~ Projects sw-arch docker docker start 597372a315ef 597372a315ef ~ Projects sw-arch docker You can also create and start a container in a single step, by using docker run: ~ Projects sw-arch docker docker run -d -p 8081:80 httpd 5a3280c5fc90340419f8f17603580e1c46fb5349a786f0ff837908f0ccfb623b Build an image We can use the docker build command to build an image. We will explain this command in the next section. Other commands An exhaustive list of all the Docker CLI commands can be found here.. The Dockerfile But how we can create an image from scratch? In Docker exists a special file, called Dockerfile, that permits the definition of an image in a script way. Let’s see how it works. The first step involves creating a new text file named Dockerfile, without extension. In this file, we are going to describe all the step-by-step commands that the Docker Engine needs to run to assemble a Docker image. We are going to explain how a Dockerfile works by looking at the getting started web application. So, start the container previously created from the docker getting-started image (or create a new one from that image) and go to the web app. Follow the first steps (Getting your app). Then, inside the app folder, create an empty file named Dockerfile and insert the following lines: FROM node:18-alpine WORKDIR app COPY . . RUN yarn install --production CMD [\"node\", \"src index.js\"] What do these commands mean? Let’s see one by one. FROM node:18-alpine: as you can notice, we downloaded a node application. The FROM command tells us the base image: in this case, since we are dealing with a node app, we want to start with a node image. WORKDIR app: this says that the default working directory for the next commands is the app folder. If the folder does not exist in the image, this command will create it. COPY . .: this command permits us to copy files from our machine to the Docker image. The syntax is COPY , in our case, the src is the current folder of our host, and the destination is the current workdir of the image that we are going to create. RUN yarn install --production: this commands launch yarn. yarn is a package manager for node, it permits the installation of all the necessary external dependencies for our project, defined inside the package.json file. CMD [\"node\", \"src index.js\"]: tells what command needs to be launched when we start a container created from the current image. For our case, we are going to start the node server. RUN and CMD: what’s the difference? RUN and CMD commands seem very similar. The main difference is that RUN is an image-build step. That is to say, all commands launched with RUN will be persistent in the image. We could have multiple RUN commands in a Dockerfile, and these commands are layered on top of one another to build the final image. CMD, instead, is the command launched by default when we start the container. The Dockerfile will just use the last CMD defined. In other words: CMD commands will be executed once during the creation of the image. The RUN command will be executed every time we start a container. Build the image To build the image we use the docker build command. Go into the folder in which the Dockerfile lives and launch the next command: docker build -t simple-node-app . This command creates a new image executing the commands specified in the Dockerfile: first, it will fetch the node:18-alpine image from the web. Then, it will copy the application inside the app folder with the COPY command and then it will run yarn to install all the dependencies. The -t flag permits to tag and name the image. The last point (.) at the end of the command tells Docker to fetch the Dockerfile from the current directory. Now, if you open Docker Desktop, you should see the newly created image: Create and run a container for our image: docker run -d -p 3200:3000 simple-node-app With the flag -d we are going to tell Docker to run the container in detached mode, while with -p we can specify the port mapping: in our case, we are mapping the 3200 port of our host to port 3000 of the container. The application is then avaiable at localhost:3200: Other Dockerfile commands Here we see briefly two other important Dockerfile commands: a complete list can be found here. EXPOSE: informs Docker that the container listens on specified network ports at runtime, and permits to specify also if the port listens on TCP or UDP protocol (default TCP if the protocol is omitted). For example: EXPOSE 80 udp EXPOSE 80 tcp EXPOSE 40 This tells that the container listens on port 80 both in UDP and TCP, and on port 40 in TCP. ENV: sets an environment variable in the container. For example, try to create this Docker image: FROM ubuntu ENV TEST_ENV_VAR=\"HELLO WORLD\" CMD [\"sleep\", \"3600\"] And run a container from it. Then, open the container’s terminal and print out the content of the environment variable TEST_ENV_VAR: Exercises Create a Dockerfile that prints “installing!” when it is installed and prints “running!” each time it is launched. Previous: Docker - Getting Started Next: Docker - Volumes"
					}

					
				
			
		
			
				
					,
					

					"docker-getting-started": {
						"id": "docker-getting-started",
						"title": "2. Getting Started",
						"category": "",
						"url": " /docker/getting-started/",
						"content": "Contents The Docker Hub Image tags Getting Started Exercises In this section, we will see step-by-step how we can create images and initialize containers. To follow properly, you should have Docker Desktop (or at least the Docker Engine if you want to do it from the CLI) installed properly on your machine. The Docker Hub We want now to play around with Docker to understand better how it works. We will use, for now, the GUI client of Docker. The easier way to see Docker in action is to download pre-defined images from the Docker Hub. The Docker Hub is a container image registry. From Docker Hub, you can fetch ready-to-use images from which you can base your application. Do you want to deploy in a container an application written in Python? You can download a Docker image that has python already installed and configured. Image tags A docker image has a tag. This permits you to specify which version of the Docker image you want to use. For example, suppose that your python application relies on libraries that were developed with python 3.9. Probably you don’t want to use the latest version of python, since the library could not work properly on python &gt;= 3.9. So, you should use a python 3.9 Docker image. You can see the available tags of an image directly from the image page of the Docker Hub: Getting Started From Docker Desktop, click on the search input field and type “docker getting-started”: On the search results pop-up, click on “Pull” on the first result: This will download a Docker Image that contains a simple tutorial. The download requires a bit, and at the end, you should find the getting-started images inside the images tab: Now click on the “Play” button of the image. A pop-up that permits setting up the container should appear. From here, you can set a container name, a host port, volumes, and environment variables. Insert only a Host port (for example, 8080) and a name (the latter is facultative), and click on “Run”. This will create and run a container from the getting-started image. You can find the newly created container on the Container tab of Docker Desktop: To see the deployed application in action, go on localhost:8080 (or, if you choose a different host port, substitute the port on the URL). If you see something like this, it means that you have launched your first container correctly :) : We will turn back on this later. Now it is time to see how we can interact with the container with Docker Desktop. From the container tab, you can stop, pause, restart, and delete containers. If you click on the container name, you can find a simple interface that permits you to see the container logs and some statistics (like, for example, CPU and memory usage), access the container’s files, and interact with the container using a terminal: Exercises Try to install python3 inside the container created on the Getting Started section (apk add –update –no-cache python3 &amp;&amp; ln -sf python3 usr bin python) and launch a python minimal hello world from the container. Experiment with environmental variables. Create a new container from the getting-started image with an environment variable. Install python also on this container (as we said in the previous lessons, the edits we do in a container remain in the container layer - parent image layers are read-only) and try to print out the environment variable from a python script (see the os python standard module). Previous: Docker - Introduction Next: Docker - CLI and Dockerfile"
					}

					
				
			
		
			
				
					,
					

					"docker-introduction": {
						"id": "docker-introduction",
						"title": "1. Introduction",
						"category": "",
						"url": " /docker/introduction/",
						"content": "Contents Install Docker Desktop The Docker Engine Containers Images Install Docker Desktop Download Docker Desktop from here. Then, run the installer and follows the onscreen instruction. This will install the Docker Engine, which is the core of the Docker platform, and an easy-to-use Graphical User Interface (GUI), i.e. Docker Desktop. The Docker Engine The Docker Engine is shipped out with a Command-Line Interface (CLI), and a server. The latter component runs as a root-privilege background process (daemon). You can interact with the server using the CLI client or Docker Desktop. The daemon creates and manages Docker objects, such as images and containers. Launching Docker Desktop will automatically start the underlying daemon process. Containers As you may have learned from the video, Docker is a tool that permits running an application in an isolated environment, enabling the capability to separate applications from infrastructures. This environment is named container and can be seen as a sandboxed process running on a machine. In a single machine, you can have multiple containers, each of one containing one or more applications. According to docker documentation, “a container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another”. Docker containers are: Industry standard: they could be portable anywhere. Lightweight: containers are not required to run a full OS per application, since all the containers share the machine’s OS system kernel. Secure: containers are isolated from the overall system, and this permits to running applications in containers safely. Docker automates the deployment of applications into containers, providing a set of tools and mechanisms that allow its management. Images A container is a runnable instance of an image. Images are the building part of Docker’s life cycle, and they are made up of filesystems layered over each other using a union mount. Every layer of an image is mounted in read-only and is itself an image: the image below is called the parent image, whereas the final is called base image. When we create a container from an image, Docker will add a read-write filesystem on top of all the image layers. This layer runs the application that we want to “Dockerize”. When Docker first starts a container, this read-write layer is empty. Changes are applied only to this layer: for example, if the running application needs to change a file of the parent image, this file is copied into the container layer (i.e., the read-write layer), shadowing the read-only file. To better understand this concept, just observe the image below: This figure depicts the layered structure of an image: starting from the bottom, we have a Kernel layer (bootfs): this layer, transparent to the user, exists for booting purposes. When the container has booted, this layer is unmounted, to free up the memory. Then, we will find the Base Image: this represents the starting point of our layered image. Usually, base images are basic minimal Linux distributions, for example, Ubuntu, Redhat, Centos, Alpine, or Debian. The next layer is the parent image of our image: simply it adds emacs (a CLI text editor) to our base image, Debian. Our image is built on top of Debian + emacs and provides an Apache HTTP server. The last layer is the read-write layer of the container, and inside of it lives the actual app. Next: Docker - Getting Started"
					}

					
				
			
		
			
				
					,
					

					"docker-volumes": {
						"id": "docker-volumes",
						"title": "4. Volumes",
						"category": "",
						"url": " /docker/volumes/",
						"content": "Contents A Glimpse of our Node Application Updating the App Where are my data? Docker Volumes A Glimpse of our Node Application In the previous section, we saw how to create a Dockerfile and we deployed our first application inside a container: If you go to the web app, you should see something like this: This demo application is a simple to-do list. Let’s try to add something: As you can notice, the inserted data seems persistent (spoiler: they are not): try to refresh the page, or to restart the container. The items that we inserted remain. Let’s see how it’s done by looking at the source code of the application. Even if we don’t know how nodeJS works (it is not part of the course), we can see that underlying the application there is a database (src persistence folder), and looking at the src persistence index.js file we know that, since we didn’t have set an environment variable MYSQL_HOST we are using SQLite. SQLite stores data in etc todos todo.db (line 3 of sqlite.js): We can prove it just by inspecting the todo.db file: Updating the App Now, suppose that you need to update the application (follow the “Updating our app” section of the getting-started application, note that we changed the name of the image in simple-node-app): This requires to rebuild the image and to create a new container. As you can imagine, our data is gone (Why?). Where are my data? Our data is gone because it lives inside a container, and updating an app requires building a new container. This is not optimal: suppose that our app is widely used around the world and therefore we have multiple servers (and multiple containers) that host the application for load-balancing purposes. We want the data to persist among containers and among different updates. What we can do? Docker Volumes To ensure the persistence of data, volumes come to our help. A volume is a way of mounting directories files from our host machine to the docker container. We can create a volume with the next command: docker volume create &lt;name&gt; Where &lt;name&gt; is the name of the volume. So let’s create a volume for our application: ~ Projects sw-arch docker getting-started docker volume create todolist-db todolist-db ~ Projects sw-arch docker getting-started You should see the volume inside Docker Desktop: Now we want to our app use this volume. In order to do so, destroy the container and create it by launching the next command: ~ Projects sw-arch docker getting-started docker run -d -p 3200:3000 -v todolist-db: etc todos simple-node-app aa68638a2fa01e8f499a916f5f8bd2f0d59c25c73ef3ebaeeb9354c8e5a50490 ~ Projects sw-arch docker getting-started The -v flag permits to specify the volume: the string “todolist-db: etc todos simple-node-app” means that the todolist-db volume is mounted in etc todos, so all the content that the application generates inside the etc todos folder will be stored inside the container. Try to do some tests: add some entries in the todo list, then destroy and recreate the container. You should note the persistence of the information. Try also to launch multiple containers with different binding ports and see with your eyes. Previous: Docker - CLI and Dockerfile"
					}

					
				
			
		
			
				
					,
					

					"gradle-build-gradle": {
						"id": "gradle-build-gradle",
						"title": "2. build.gradle",
						"category": "",
						"url": " /gradle/build.gradle/",
						"content": "Contents Anatomy of build.gradle Plugins Application Repositories Dependencies Resolving dependencies Tasks Anatomy of build.gradle The build.gradle file contains the configuration that tells gradle how to build the project: inside of it, we have for example the definition of the external dependencies of the project and where to fetch them, and user-defined tasks. This is the build.gradle file from the previous example: plugins { id(\"application\") } group = \"org.example\" version = \"1.0-SNAPSHOT\" repositories { mavenCentral() } dependencies { testImplementation(platform(\"org.junit:junit-bom:5.9.1\")) testImplementation(\"org.junit.jupiter:junit-jupiter\") } application { mainClass.set(\"org.example.Main\") } tasks.test { useJUnitPlatform() } Let’s see the meaning of each block. Plugins plugins { id(\"application\") } A Gradle plugin consists of an enhancement of Gradle core that specifies how to build and run the code, targetting specific build type and providing already-defined tasks. Each programming language has its own plugin. If you remember, in the last lesson we changed to the build.gradle, substituting the Java plugin with the application one. We did it because the application plugin is an extension of the Java plugin (in other words, it inherits all the tasks of the Java plugin) that adds, among other things, the “run” task that permits, as we have seen, to run the application. As documentation says, “java plugin adds basic building blocks for working with JVM projects. Its feature set has been superseded by other plugins, offering more features based on your project type. Instead of applying it directly to your project, you should look into the java-library or application plugins or one of the supported alternative JVM language.”. The documentation explain well the application plugin. To summarize, a Plugin is just an extension of the Gradle core that adds tasks and functionality to it. If we want to be more specific, a Gradle plugin can: Extend the Gradle model (for example, adding new DSL elements that can be configured) Configure the project according to conventions (for example, adding new tasks) Apply specific configuration (for example, enforcing organizational standards) Application application { mainClass.set(\"org.example.Main\") } This block is specific to the application plugin. It tells Gradle that the Main Class of the program (i.e. our entry point) is the class org.example.Main (note that the name should be fully qualified). This is an example of an extension of the Gradle model. Repositories repositories { mavenCentral() } There exist some repositories that host libraries for projects. In the repositories block, you can specify which repositorie to use. In our example, we use Maven Central, but we can have more than one repository. Let’s see another example: repositories { mavenCentral() google() maven { url = uri(\"https: repository.jboss.org maven2\") } } Here we have multiple repositories. This means that, if we want to fetch a library named “mickeymouse”, if the library does not exist in the first repository declared, gradle will check the existence on the next repository in the list, until it finds something. Let’s see these repositories: mavencentral() is just a function that returns the maven central library URL. google() is the google maven library. the maven block with url variable is a special block that permits the declaration of a custom repository just by adding its URL. Note that these are just examples, and we redirect curious readers to the official documentation. Dependencies dependencies { testImplementation(platform(\"org.junit:junit-bom:5.9.1\")) testImplementation(\"org.junit.jupiter:junit-jupiter\") } In this block, we define all the dependencies (i.e. libraries and or frameworks) used by the project. We can have different types of dependencies because we could have different dependencies for different scopes. For example, some dependencies should be used for compiling source code whereas others only need to be available at runtime, or only for executing tests. In our build.gradle we have defined some testImplementation, that is, dependencies only used for testing. Let’s see the meaning of the second line: as you can notice, we have a function, testImplementation. This defines the configuration, i.e. the scope. A scope can be defined in plugins or by the user. For example, for the Java plugin, we have different scopes (we will see here a few of them): compileOnly: dependencies used only in compile-time. runtimeOnly: dependencies used only in run-time. testImplementation: dependencies used only for testing. A comprehensive explanation of Java Plugin dependencies can be found here. Note that since Application is an extension of the Java plugin, these scopes are available also if you are using the Application plugin. In the next lesson, we will see an example of how we can import (and use) a dependency. “org.junit.jupiter:junit-jupiter” is the dependency that we want to import. The substring before ‘:’ represents the group (i.e., it is an identifier of an organization, company, or project). After the ‘:’ we have the name of the dependencies (in our case, junit-jupiter). In addition, you could also have another ‘:’ after the name and the last part of the string represents the version of the dependency that you want to use. For example, the first dependency (that has group org.junit, and name junit-bom) is bound to version 5.9.1. If the version is omitted, then Gradle will fetch the latest version of the dependency. This is not always optimal, because if a new version of a runtimeOnly dependency that you are using ships out, the next build of your app could fetch the newer version, and, if the developers introduce some breaking changes, then these changes may break your app. It is important to say that before using a dependency the developer should check his reliability: is the dependency regularly updated? How many people used it? Does the publisher have a good reputation? Resolving dependencies Gradle has a caching system for dependencies. To resolve a dependency for a project: First, Look if the artifact is in the cache. Usually, the cache is located in “~.gradle\\caches”. If this is the case, retrieve and use the artifact. If not, connect to the given repositories (the ones specified in the “repositories” block). Look to the specific group name version. Download the desired artifact and cache it. Retrieve and use the artifact. Tasks tasks.test { useJUnitPlatform() } This block configures test tasks. This task is specific to Java-related plugins. We don’t want to spend too many words on it, but if you are interested, here more information is present. Our tasks.test block says that for our project we are going to use JUnit for testing. What is JUnit? We will answer this question in the next lesson. Previous: Gradle - Introduction Next: Gradle - Testing Java Applications"
					}

					
				
			
		
			
				
					,
					

					"gradle-example-log4j": {
						"id": "gradle-example-log4j",
						"title": "4. Example - log4j",
						"category": "",
						"url": " /gradle/example-log4j/",
						"content": "Contents Logging Log level Exercises Here, we will see an example of how we can add a dependency to our Gradle project. For this purpose, we will present a Java logging library, Log4j. Logging When you write software, it is useful to introduce logs. Logs can help, for example, to record the execution of events in your application, to identify and understand the pattern of activities, and to identify the source of problems in case of software incidents. Log4j is a library that enhances the main logging mechanism of Java. To use Log4J in a Java Gradle project, we follow what the documentation says and we add the dependencies. Our build.gradle file should look like this: plugins { id(\"application\") } group = \"org.example\" version = \"1.0-SNAPSHOT\" repositories { mavenCentral() } dependencies { implementation(\"org.apache.logging.log4j:log4j-api:2.20.0\") implementation(\"org.apache.logging.log4j:log4j-core:2.20.0\") testImplementation(\"org.junit.jupiter:junit-jupiter-api:5.9.0\") testRuntimeOnly(\"org.junit.jupiter:junit-jupiter-engine:5.9.0\") } application { mainClass.set(\"org.example.Main\") } tasks.test { useJUnitPlatform() } Then, we can just start using the log4j library directly on our application: package org.example; import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; public class Main { private static final Logger logger = LogManager.getLogger(\"Main\"); public static int add(int a, int b) { return Math.addExact(a, b); } public static void main(String[] args) { int a = Integer.parseInt(args[0]); int b = Integer.parseInt(args[1]); int result = Main.add(a, b); logger.info(\"Hello World from log4j\"); } } However, nothing is printed out in the console. This is because we need to configure the log4J library. To do so, create a file in src main resources, named “log4js2.xml”, with this content: &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;Configuration status=\"INFO\"&gt; &lt;Appenders&gt; &lt;Console name=\"Console\" target=\"SYSTEM_OUT\"&gt; &lt;PatternLayout pattern=\"%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\" &gt; &lt; Console&gt; &lt;File name=\"File\" fileName=\". logs log.log\" immediateFlush=\"false\" append=\"false\"&gt; &lt;PatternLayout pattern=\"%d{yyy-MM-dd HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\" &gt; &lt; File&gt; &lt; Appenders&gt; &lt;Loggers&gt; &lt;Root level=\"debug\"&gt; &lt;AppenderRef ref=\"Console\" &gt; &lt;AppenderRef ref=\"File\" &gt; &lt; Root&gt; &lt; Loggers&gt; &lt; Configuration&gt; Here you can find additional information. Our configuration file tells log4j to log file in the console and in a file in folder logs log.log. Check it out! Log level You can classify logs based on their importance. You can do this by using the log level. A high log level means that the logged information is more important than a lower one and requires particular attention. Usually, a high level reports fatal errors and errors in general. Here are what log level log4j offers (ordered by importance): Fatal: tells that the application enters a state in which one of the crucial functionalities stopped working. Error: tells that one or more functionality doesn’t work properly. Warn: tells that something unexpected happens, but the application is not affected. Info: tells that something happens (for example, used to track that the application enters a certain state). Debug: in this level, you should put all the information that regards debugging. Trace: used when you need full visibility of what it is happening inside your application (for example, you can use trace to keep track of the control flow of your application). You can use log levels in the following way: package org.example; import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; public class Main { private static final Logger logger = LogManager.getLogger(\"Main\"); public static int add(int a, int b) { return Math.addExact(a, b); } public static void main(String[] args) { int a = Integer.parseInt(args[0]); int b = Integer.parseInt(args[1]); int result = Main.add(a, b); logger.trace(\"Hello World from log4j\"); logger.debug(\"Hello World from log4j\"); logger.info(\"Hello World from log4j\"); logger.warn(\"Hello World from log4j\"); logger.error(\"Hello World from log4j\"); logger.fatal(\"Hello World from log4j\"); } } ~ IdeaProjects Gradle-GettingStarted . gradlew run &gt; Task :run 15:45:27.762 [main] DEBUG Main - Hello World from log4j 15:45:27.763 [main] INFO Main - Hello World from log4j 15:45:27.763 [main] WARN Main - Hello World from log4j 15:45:27.763 [main] ERROR Main - Hello World from log4j 15:45:27.764 [main] FATAL Main - Hello World from log4j BUILD SUCCESSFUL in 1s 3 actionable tasks: 2 executed, 1 up-to-date ~ IdeaProjects Gradle-GettingStarted Exercises Define a class Student that has a name, a surname, a matriculation number, and a list of passed Courses. Then, write a test function that creates a Student and adds some courses to its list. Log the created Student in a log entry in JSON format using the gson library and log4j. Previous: Gradle - Testing Java Application"
					}

					
				
			
		
			
				
					,
					

					"gradle-introduction": {
						"id": "gradle-introduction",
						"title": "1. Introduction",
						"category": "",
						"url": " /gradle/introduction/",
						"content": "Contents What is Gradle Installation Gradle in Action Command-Line Gradle A Quick Note About DSL What is Gradle Gradle is an open-source build automation tool, that is, a tool that permits developers to automatize tasks like, for example, test execution, code compiling, deployment, and generation of documentation. It is the most popular build system for the Java Virtual Machine (JVM) and the default for Android. The peculiarity of Gradle is that it provides its own high-level and declarative build language that permits writing build logic with ease. In this course, we will focus only on the compilation part of Gradle for Java applications. Installation You can install gradle in many different ways: Installing IntelliJ IDEA: Gradle will be installed by default (Recommended). Installing the &lt;a target=”_blank” rel=”noopener noreferrer” href=”https: code.visualstudio.com docs javJava Extension Pack for Visual Studio Code. Manual installation (just follow the documentation). For this course, we will use Gradle with IntelliJ IDEA. NOTE: Two versions of IntelliJ IDEA exist: Community Edition, which is free, and Ultimate, which is not. The Ultimate version has the support for Spring (that we will see in the next lessons). However, you can obtain a free Student License to use IntelliJ Ultimate (see here). Gradle in Action To see Gradle in action create a new Project with IntelliJ IDEA and choose Gradle as Build System. Set the other parameters as follows: Now open the build.gradle.kts and replace all the content with the next snippet of code (we will explain why in the following sections): plugins { id(\"application\") } group = \"org.example\" version = \"1.0-SNAPSHOT\" repositories { mavenCentral() } dependencies { testImplementation(platform(\"org.junit:junit-bom:5.9.1\")) testImplementation(\"org.junit.jupiter:junit-jupiter\") } application { mainClass.set(\"org.example.Main\") } tasks.test { useJUnitPlatform() } Then, click on the elephant icon highlighted by the arrow in the image below (or, if you don’t see it, just reopen the project). This action syncs the IntelliJ Gradle plugin with the changes we made. Now open the Gradle view (the elephant on the left): here, you have a list of all the Gradle tasks that you can launch. A task is a piece of work that Gradle can do with a project. For example, the build task will perform all the steps necessary to get a full build of our Java application. Double-click on it. This will open a run panel on the lower side of the IDE that shows what your action does. You should see something like this: 20:22:13: Executing 'build'... &gt; Task :compileJava &gt; Task :processResources NO-SOURCE &gt; Task :classes &gt; Task :jar &gt; Task :startScripts &gt; Task :distTar &gt; Task :distZip &gt; Task :assemble &gt; Task :compileTestJava NO-SOURCE &gt; Task :processTestResources NO-SOURCE &gt; Task :testClasses UP-TO-DATE &gt; Task :test NO-SOURCE &gt; Task :check UP-TO-DATE &gt; Task :build BUILD SUCCESSFUL in 328ms 5 actionable tasks: 5 executed 20:22:14: Execution finished 'build'. As you can notice, some tasks were called sequentially, and a new folder appeared in your project. If you navigate on it, you can see that it contains different subfolders: classes, distributions, generated, libs, and so on. On these folders you get your application in different “formats”: for example, you get it as a .jar library, as a set of .class files, or as archives (.zip and .tar) for distribution. Now double-click on the run task, under the application folder: 20:49:10: Executing 'run'... &gt; Task :compileJava UP-TO-DATE &gt; Task :processResources NO-SOURCE &gt; Task :classes UP-TO-DATE &gt; Task :run Hello and welcome!i = 1 i = 2 i = 3 i = 4 i = 5 BUILD SUCCESSFUL in 163ms 2 actionable tasks: 1 executed, 1 up-to-date 20:49:11: Execution finished 'run'. This action will perform all the necessary steps to run the application: as you can see, first it will call the compileJava task (that as the name suggests compile the Java application) and generate a .class file. In this case, we did not generate .jar, .zip, and .tar files, because we just wanted to run the application. Command-Line Gradle A keen eye might have noticed that on the root folder of our project, there are two script files: gradlew and gradlew.bat. These files are wrappers of gradle and permit launching tasks directly from the terminal. Just try to launch . gradlew tasks (if you are on macOS Linux) or gradlew.bat tasks (if you are on Windows). This command will list all the available tasks. You can launch tasks by . gradlew &lt;task&gt; (or . gradlew.bat &lt;task&gt;), replacing &lt;task&gt; with the task name. For example: A Quick Note About DSL Maybe you noticed that during the creation of the project you could choose the Gradle DSL (Domain Specific Language). This goes to specifies the language that you want to use for your Gradle build file (more details on this file later). Kotlin is the preferred choice since it is more readable and offers better compile-time checks since Kotlin is statically typed. However, syntax differences are minimal, so you can choose whatever you prefer. Next: Gradle - build.gradle"
					}

					
				
			
		
			
				
					,
					

					"gradle-testing-java-applications": {
						"id": "gradle-testing-java-applications",
						"title": "3. Testing Java Applications",
						"category": "",
						"url": " /gradle/testing-java-applications/",
						"content": "Contents Testing Unit Testing and Integration Testing JUnit The importance of writing tests that make sense Exercises Testing Testing is a program analysis technique that aims to check the correctness of a piece of code just by observing its executions. Suppose that we have this Java application: package org.example; public class Main { public static int add(int a, int b) { return Math.addExact(a, b); } public static void main(String[] args) { int a = Integer.parseInt(args[0]); int b = Integer.parseInt(args[1]); int result = Main.add(a, b); System.out.println(\"The result is \"+result); } } We want to check if the function adds behaves correctly. The function should return the sum of two integers: if we have, for example, 3 and 4, Main.add should return 7. We can check manually by running the main method. As you can see, the main function takes in input the two numbers to add as arguments. With the “run” task of gradle, one can pass arguments using the flag –args, as the next example shows: ~ IdeaProjects Gradle-GettingStarted . gradlew run --args=\"3 4\" &gt; Task :run The result is 7 BUILD SUCCESSFUL in 799ms 2 actionable tasks: 1 executed, 1 up-to-date ~ IdeaProjects Gradle-GettingStarted The function seems to behave correctly. But what we can say for all the other integers? We didn’t know. Let’s try some other cases: ~ IdeaProjects Gradle-GettingStarted . gradlew run --args=\"-3 -10\" &gt; Task :run The result is -13 BUILD SUCCESSFUL in 810ms 2 actionable tasks: 1 executed, 1 up-to-date ~ IdeaProjects Gradle-GettingStarted . gradlew run --args=\"56 -1\" &gt; Task :run The result is 55 BUILD SUCCESSFUL in 728ms 2 actionable tasks: 1 executed, 1 up-to-date ~ IdeaProjects Gradle-GettingStarted . gradlew run --args=\"452 123\" &gt; Task :run The result is 575 BUILD SUCCESSFUL in 770ms 2 actionable tasks: 1 executed, 1 up-to-date ~ IdeaProjects Gradle-GettingStarted . gradlew run --args=\"-452 123\" &gt; Task :run The result is -329 BUILD SUCCESSFUL in 717ms 2 actionable tasks: 1 executed, 1 up-to-date ~ IdeaProjects Gradle-GettingStarted What we are doing here is called manual testing: it requires that a person (tester) put himself in the shoes of an end-user to test the application’s features to ensure correct behavior. However, testing an application this way could be time-consuming and costly, and often could lead to human error. Automated Testing comes with our help: it is a testing method that permits the definition of tests in a programmable way. The idea is to write some software to check automatically the execution of our program. The intuition is that instead of manually trying some combinations of numbers and checking that the sum provided by our program is correct, we can define a set of cases that we want to test and then run automatically software that controls that these cases produce the correct results. This lesson aims to show how we can use a Java Framework (JUnit) that permits us to write and run tests. The benefits of using an automated test arise with more complex examples: suppose that you wrote a function that does something and you are manually testing it. You want to test 100 distinct input values to be sure that your function behaves correctly. So you start testing, and on the 99th test, you find that something is wrong. In that case, you need to fix the code, and you need to redo all the tests! This requires a lot of time, and having an automated testing mechanism permits testing all the inputs at once. NOTE: this doesn’t mean that manual testing is useless, indeed it is required in the early phase of the software development, before automating, to check automation feasibility. In addition, when you download and try a beta version of an application, you are actually performing some sort of manual testing. Unit Testing and Integration Testing Before going into details, it is necessary to say something about different testing processes. Here we will focus on Unit Testing, that is, testing the correctness of software components (for example, a function or a class) in isolation. This is the first phase of testing and it is considered white-box testing: these tests are performed by a developer that knows the internal design of the software. If we want to test how two or more software components interact with each other we need to talk about integration testing. Integration tests are performed after unit tests and don’t require a knowledge of the internal design of the software (black-box testing). The idea here is to test the correctness of the interface between software units (for example, testing that if you log in to a website you will be redirected to your account page). JUnit JUnit is a unit testing framework for the Java programming language. Let’s see how it works. First, we need to add JUnit dependencies in our build.gradle file (use the Gradle-GettingStarted project, and replace the Main class with the one provided in this lesson). dependencies { testImplementation(\"org.junit.jupiter:junit-jupiter-api:5.9.0\") testRuntimeOnly(\"org.junit.jupiter:junit-jupiter-engine:5.9.0\") } testImplementation is a configuration that tells the required dependencies used for compile tests. testRuntimeOnly defines the dependencies required only at test runtime. Now, inside src test java, create a class called UnitTests and insert these lines: import org.example.Main; import org.junit.jupiter.api.Test; public class UnitTests { @Test public void testAdd() { if (Main.add(12, 34) != 46) { throw new ArithmeticException(\"Wrong!\"); } } } Before going further, let’s spend some words on the method testAdd. The @Test annotation tells that the method is a test method. The body of the method is self-explanatory: simply, it checks that the value returned by the method add is correct, if not, it raises an exception. This simulates what we did “by hand” just some minutes ago. If the test raises an error, it means that there is something wrong with the method. You can run tests with gradlew from the terminal. . gradlew test --tests # launch all the defined test methods . gradlew test --tests 'UnitTests.testAdd' # launch test method testAdd of class UnitTests If you are using IntelliJ, probably you have noticed that a play button appears on the right of the method signature: If you click on it, you can run the test, or among the other things you can run the test with coverage. Choose run with coverage. Now, on the right, a window will appear telling you the coverage (i.e. the percentage of your code that your test reaches: for our case, we cover all the classes, 50% of methods (1 method of 2), and the 20% of code lines). of your test. Open the Main class and notice the green shape on the left of the function “add”. This means that the “testAdd” function executes the function completely. Of course, we didn’t call the “main” method from the test, so the main has no coverage (highlighted in red). The importance of writing tests that make sense Our test passed successfully and covered all the lines of our add function. But are we really, really, really sure that the function is bug-free? Spoiler: no. To tell you why, we need a more complex example. Suppose that we have this function, that checks if two String has the same amount of 0s: public static boolean equalZero(String a, String b) { int countA = 0; int countB = 0; for (int i = 0; i &lt; a.length(); i++) { if (a.charAt(i) == '0') { countA += 1; } } for (int i = 0; i &lt; a.length(); i++) { if (b.charAt(i) == '0') { countB += 1; } } return countA == countB; } End we have this test: @Test public void testEqual0() throws Exception { if (!Main.equalZero(\"Hell0\", \"Hell0 World!\")) { throw new Exception(\"Wrong!\"); } if (!Main.equalZero(\"0100001111\", \"10000101111\")) { throw new Exception(\"Wrong!\"); } if (Main.equalZero(\"0\", \"1\")) { throw new Exception(\"Wrong!\"); } if (!Main.equalZero(\"\", \"11\")) { throw new Exception(\"Wrong!\"); } if (!Main.equalZero(\"\", \"\")) { throw new Exception(\"Wrong!\"); } } Let’s try to launch the test: ~ IdeaProjects Gradle-GettingStarted . gradlew test --tests 'UnitTests.testEqual0' Deprecated Gradle features were used in this build, making it incompatible with Gradle 9.0. You can use '--warning-mode all' to show the individual deprecation warnings and determine if they come from your own scripts or plugins. For more on this, please refer to https: docs.gradle.org 8.2 userguide command_line_interface.html#sec:command_line_warnings in the Gradle documentation. BUILD SUCCESSFUL in 1s 3 actionable tasks: 3 executed ~ IdeaProjects Gradle-GettingStarted As you can see, the test passed. We tried empty strings, strings with different lengths, and strings without zeros. We can also convince ourselves that the function is correct. But… Let’s add this test case: if (Main.equalZero(\"0011\", \"11000\")) { throw new Exception(\"Wrong!\"); } Launch the test and notice the error. This simple example aims to show that sometimes a bug can hide itself well in the code, and even if we have defined multiple test cases and covered all the lines of a method bugs can remain unnoticed. To have meaningful tests, it is important to reason about all the borderline cases. Exercises Fix the equalZero function. Can you improve the modularity of this function? You have this Java class: package org.acme; class QuickSort { static void swap(int[] arr, int i, int j) { int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; } static int partition(int[] arr, int low, int high) { int pivot = arr[high]; int i = (low - 1); for (int j = low; j &lt;= high - 1; j++) { if (arr[j] &lt; pivot) { i++; swap(arr, i, j); } } swap(arr, i + 1, high); return (i + 1); } static void sort(int[] arr, int low, int high) { if (low &lt; high) { int pi = partition(arr, low, high); sort(arr, low, pi - 1); sort(arr, pi + 1, high); } } } Create a Main class that uses the method “sort”, and write a build.gradle file for the project. Write also some tests. Previous: Gradle - build.gradle Next: Gradle - Example: log4j"
					}

					
				
			
		
	};
</script>
<script src="/scripts/lunr.min.js"></script>
<script src="/scripts/search.js"></script>

			</article>
		</section>

		<script>
			document.getElementById("open-nav").addEventListener("click", function () {
				document.body.classList.toggle("nav-open");
			});
		</script>
	</body>
</html>
